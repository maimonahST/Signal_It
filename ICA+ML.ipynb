{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "import scipy.io\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import TransformerMixin,BaseEstimator\n"
      ],
      "metadata": {
        "id": "ORtdnfUWq2rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vJmpV4Ayq6Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPDpoI8QqvXh"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import scipy.io\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "x = np.load('/content/drive/MyDrive/GP-Data/X_ica2.npy')\n",
        "y = np.load('/content/drive/MyDrive/GP-Data/y_ica2.npy')\n",
        "\n",
        "\n",
        "print(x.shape,y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[y==0] = 1 #Stroke\n",
        "y[y==2] = 0 #Healthy"
      ],
      "metadata": {
        "id": "smDqDJqXq4Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import train_test_split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=101)\n"
      ],
      "metadata": {
        "id": "EoqUEDeCq9B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training data: {X_train.shape[0] / x.shape[0] * 100:.2f}%\")\n",
        "#print(f\"Validation data: {X_val.shape[0] / x.shape[0] * 100:.2f}%\")\n",
        "print(f\"Test data: {X_test.shape[0] / x.shape[0] * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "KkJNztc2q-ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the data array for ML models\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "# X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "y_train = y_train.reshape(y_train.shape[0], -1)\n",
        "# y_val = y_val.reshape(y_val.shape[0], -1)\n",
        "y_test = y_test.reshape(y_test.shape[0], -1)\n"
      ],
      "metadata": {
        "id": "2NoL2vRhrAT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_and_evaluate(X_train, y_train, X_test, y_test,model):\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Predictions on the test set\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # Calculate evaluation metrics\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred, average='weighted')\n",
        "  recall = recall_score(y_test, y_pred, average='weighted')\n",
        "  f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "  # Print the results\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(\"Recall:\", recall)\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"F1-score:\", f1)\n",
        "\n",
        "\n",
        "  print(\"Classification Report (Test):\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "  # Compute the confusion matrix for the test set\n",
        "  cm_test = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  # Plot the confusion matrix for the test set\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "  plt.xlabel(\"Predicted Label\")\n",
        "  plt.ylabel(\"True Label\")\n",
        "  plt.title(f\"Confusion Matrix for Decision Tree {model.__class__}\")\n",
        "  plt.show()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "39FormrOrB4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "model=fit_and_evaluate(X_train, y_train,X_test , y_test,KNeighborsClassifier(algorithm='auto', n_neighbors=15, weights='uniform'))\n"
      ],
      "metadata": {
        "id": "dTxnWNystu_N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}